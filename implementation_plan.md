# RAG Chatbot Implementation Plan

## Goal
Create an interactive Chatbot that allows users to upload a Knowledge Base (KB) and ask questions, receiving answers generated by an LLM based on the retrieved context.

## User Review Required
- **LLM Provider**: We will default to using `langchain` with OpenAI or Google Gemini. The user will need to provide an API Key in the UI.
- **KB Format**: We will support `.txt` and `.md` files initially.

## Proposed Changes
We will create a new Streamlit application in `rag_chatbot`.

### `rag_chatbot`
#### [NEW] requirements.txt
- streamlit
- langchain
- langchain-community
- langchain-openai
- langchain-google-genai
- chromadb
- python-dotenv
- tiktoken

#### [NEW] app.py
- Main Streamlit interface.
- Sidebar for API Key input and File Upload.
- Chat interface for Q&A.
- RAG Pipeline integration.

#### [NEW] rag_engine.py
- Functions to load documents.
- Functions to split text.
- Functions to create vector store (Chroma).
- Retrieval chain setup.

## Verification Plan
### Manual Verification
1. Run the app: `streamlit run app.py`
2. Enter API Key.
3. Upload a sample KB file.
4. Ask a question about the content.
5. Verify the response is accurate.
